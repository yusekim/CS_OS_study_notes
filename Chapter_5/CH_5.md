## 5.1 기본 개념 Basic Concepts
다중 프로그래밍의 목적은 CPU이용률을 최대화하기 위해 항상 실행 중인 프로세스를 가지게 하는 데 있다.

- **CPU-I/O 버스트 사이클 CPU-I/O Burst Cycle**
	프로세스의 실행은 CPU 실행과 I/O대기의 사이클로 구성된다.
	프로세스 실행은 CPU 버스트로 시작된다. 뒤이어 I/O 버스트가 발생하고, 이가 계속 반복되다가 마지막 CPU 버스트는 실행을 종료하기 위한 시스템 요청과 함께 끝난다.
<br>

- **CPU 스케줄러 CPU Scheduler**
	CPU가 유후 상태가 될 때마다, 운영체제는 준비 큐에 있는 프로세스 중에서 하나를 선택해 실행해야 한다. 선택 절차는 CPU 스케줄러에 의해 수행된다.
<br>

- **선점 및 비선점 스케줄링 Preemptive and Nonpreemptive Scheduling**
	CPU 스케줄링 결정은 다음의 네 가지 상황에서 발생할 수 있다.
	1. 한 스로세스가 실행 상태에서 대기 상태로 전환될 때(I/O 요청 또는 wait()의 호출)
	2. 프로세스가 실행 상태에서 준비 완료 상태로 전환될 때(인터럽트의 발생)
	3. 프로세스가 대기 상태에서 준비 완료 상태로 전환될 때(I/O의 종료 시)
	4. 프로세스가 종료할 때

	상황 1과 4에서만 스케줄링이 발생할 경우, 우리는 이러한 스케줄링 방법을 **비선점(nonpreemptive)** 또는 **협조적(cooperative)**이라고 한다. 그렇지 않으면, **선점(preemptive)**라고 한다.
<br>

- **디스패치 Dispatcher**
	디스패치는 CPU코어의 제어를 CPU 스케줄러가 선택한 프로세스에 주는 모듈이며 다음과 같은 작업을 포함한다.
	- 한 프로세스에서 다른 프로세스로 문맥을 교환하는 일
	- 사용자 모드로 전환하는 일
	- 프로그램을 다시 시작하기 위해 사용자 프로그램의 적절한 위치로 이동(jump)하는 일
	디스패처는 모든 프로세스의 문맥 교환 시 호출되므로, 가능한 한 최고로 빨리 수행되어야 한다. 디스패처가 하나의 프로세스를 정지하고 다른 프로세스의 수행을 시작하는 데까지 소요되는 시간을 디스패치 지연(dispatch latency)라고 한다.
<br>

## 5.2 스케줄링 기준 Scheduling Criteria
CPU스케줄링 알고리즘들은 서로 다른 특성이 있으며 부류마다 선호도가 다를 수 있다. CPU 스케줄링 알고리즘을 비교하기 위해 사용되는 기준들은 다음과 같다.
- CPU 이용률(utilization): 우리는 가능한 한 CPU를 최대한 바쁘게 유지하기를 원한다.
- 처리량(throughput): 단위 시간당 완료된 프로세스의 개수를 처리량이라고 한다.
- 총처리 시간(turnaround time): 특정한 프로세스 제출 시간과 완료 시간의 간격을 총처리 시간이라고 한다. 이는 준비 큐에서 대기한 시간, CPU에서 실행하는 시간, 그리고 I/O시간을 합한 시간이다.
- 대기 시간(waiting time): 준비 큐에서 대기하면서 보낸 시간의 합을 대기 시간이라고 부른다.
- 응답 시간(response time): 하나의 요구를 제출한 후 첫 번째 응답이 나올때까지의 시간이다.

## 5.3 스케줄링 알고리즘 Scheduling Algorithms

- **선입 선처리 스케줄링 First-Come, First-Served Scheduling**
	가장 간단한 CPU스케줄링 알고리즘(비선점), CPU를 먼저 요청하는 프로세스가 CPU를 먼저 할당받는다(FIFO 큐). 호위 효과(convoy effect 모든 다른 프로세스들이 하나의 긴 프로세스가 CPU를 양도할때까지 기다리는 현상)로 인해 CPU와 장치 이용률이 저하된다.
<br>

- **최단 작업 우선 스케줄링 Shortest-Job-First Scheduling**
	각 프로세스에 다음 CPU버스트 길이를 연관시킨다. CPU가 이용 가능해지면, 가장 작은 다음 CPU버스트를 가진 프로세스에 할당한다. 두 프로세스가 동일한 길이의 다음 CPU버스트를 가지면 선입 선처리 스케줄링을 활용한다.
	SJF 알고리즘이 최적이긴 하지만, 다음 CPU버스트의 길이를 알 방법이 없기 때문에 CPU스케줄링 수준에서는 구현할 수 없다(예측할 수는 있다).
	선점형 SJF알고리즘은 때ㄸ때로 최소 잔여 시간 우선(shortest remaining time first) 스케줄링이라고 불린다.
<br>

- **라운드 로빈 스케줄링 Round-Robin Scheduling**
	라운드 로빈 스케줄링 알고리즘은 선입 선처리 스케줄링과 유사하지만 시스템이 프로세스들 사이를 옮겨 다닐 수 있도록 선점이 추가된다.
	시간 할당량(time quantum) 또는 타임슬라이스(time slice)라고 불리는 작은 단위의 시간을 정의한다. 준비 큐는 원형 큐로 동작된다.
	CPU 스케줄러는 준비 큐에서 첫 번째 프로세스를 선택해 한 번의 시간 할당량 이후에 인터럽트를 걸도록 타이머를 설정한 후, 프로세스를 디스패치한다.
	만약 현재 실행 중인 프로세스의 CPU버스트가 한 번의 시간 할당량보다 긴 겨우, 타이머가 끝나고 운영체제에 인터럽트가 발생되어 문맥교환이 일어나고 실행하던 프로세스는 준비 큐의 꼬리에 넣어진다.
	시간 할당량과 문맥 교환 사이의 영향을 고려해 시간 할당량을 적절히 분배해야 한다.
<br>

- **우선순위 스케줄링 Priority Scheduling**
	SJF 알고리즘은 일반적인 **우선순위 스케줄링** 알고리즘의 특별한 경우이다.
	무한 봉쇄(indefinite blocking) 기아 상태(starvation) 문제가 있다.
<br>

- **다단계 큐 스케줄링 Multilevel Queue Scheduling**
	우선순위와 라운드 로빈 스케줄링을 사용할 때 큐가 관리되는 방식에 따라 우선순위가 가장 높은 프로세스를 결정하기 위해 O(n) 검색이 필요할 수 있다.
	다단계 큐는 우선순위마다 별도의 큐를 갖는 방법이며, 우선순위 스케줄링이 라운드 로빈과 결합한 경우에도 효과적이다. 우선순위가 가장 높은 큐에 여러 프로세스가 있는 경우 라운드 로빈 순서로 실행된다.
	예시로 아래와 같은 4개의 큐를 가진 스케줄링 알고리즘이 있다고 하자, 각 큐는 다음과 같은 우선순위를 갖는다.
	1. 실시간 프로세스
	2. 시스템 프로세스
	3. 대화형 프로세스
	4. 배치 프로세스
	각 큐는 낮은 우선순위의 큐보다 절대적인 우선순위를 가진다. (실시간, 시스템, 대화형 프로세스를 위한 큐가 빌 때까지 배치 큐에 있는 프로세스는 대기한다.)
<br>

- **다단계 피드백 큐 스케줄링 Multilevel Feedback Queue Scheduling**
	다단계 피드백 큐 스케줄링 알고리즘에서는 프로세스가 큐들 사이를 이동하는 것을 허용한다. 어떤 프로세스가 CPU시간을 너무 많이 사용하면, 낮은 우선순위의 큐로 이동된다. I/O 중심의 프로세스와 대화형 프로세스들은 높은 우선순위의 큐에 넣는다(짧은 CPU버스트의 영향). 마찬가지로, 큐에서 너무 오래 대기하는 프로세스들은 기아 상태를 예방하기 위해 높은 우선순위의 큐로 이동할 수 있다.
	예를 들어, 번호가 0에서 2까지인 세개의 큐를 가진 다단계 피드백 큐 스케줄러가 있다. 스케줄러는 처음에 큐 0에 있는 모든 프로세스를 실행시킨다. 큐 1은 큐 0이 비어있을때, 큐 2는 큐 0,1이 비어있을때만 실행된다. 큐 1에 도착한 프로세스들은 큐 2에 있는 프로세스를 선점한다.
	새로 진입하는 프로세스는 큐 0에 넣어진다. 큐 0에 있는 프로세스는 8밀리초의 시간 할당량이 주어지고, 그 시간 내에 프로세스가 끝나지 않는다면 큐 1의 꼬리로 이동하며 16밀리초의 시간할당량이 주어진다. 큐 1이 실행되고, 시간 할당량 내에 작업이 완료되지 않는다면 선점되어 큐 2에 넣어진다. 기아를 방지하기 위해 우선순위가 낮은 큐에서 너무 오래 대기하는 프로세스가 점차 우선순위가 높은 프로세스로 이동될 수 있다.
	일반적으로, 다단계 피드백 큐 스케줄러는 다음의 매개변수에 의해 정의된다.
	- 큐의 개수
	- 각 큐를 위한 스케줄링 알고리즘
	- 한 프로세스를 높은 우선순위 큐로 올려주는 시기를 결정하는 방법
	- 한 프로세스를 낮은 우선순위 큐로 강등시키는 시기를 결정하는 방법
	- 프로세스에 서비스가 필요할 때 프로세스가 들어갈 큐를 결정하는 방법

	이 스케줄링 알고리즘은 가장 일반적인 CPU 스케줄링 알고리즘이다. 하지만 많은 매개변수들을 고려해야하기 때문에 가장 복잡한 알고리즘이기도 한다.

## 5.3 스레드 스케줄링 Thread Scheduling
4장에서 프로세스 모델에 스레드르 도입하면서 **사용자** 수준과 **커널** 수준 스레드를 구별하였다. 대부분 최신 운영체제에서는 스케줄 되는 대상은 프로세스가 아니라 커널 수준 스레드이다.

## 5.5 다중 처리기 스케줄링 Multiple-Processor Scheduling
만일 여러 개의 CPU가 사용 가능하다면, 여러 스레드가 병렬로 실행될 수 있으므로 __부하 공유(load sharing)__ 가 가능해진다. 최신 컴퓨팅 시스템에서는 이제 **다중 처리기**는 다음 시스템 아키텍처들에 사용될 수 있다.
- 다중 코어 CPU
- 다중 스레드 코어
- NUMA 시스템
- 이기종 다중 처리

- **다중 처리기 스케줄링에 대한 접근 방법 Approaches to Multiple-Processor Scheduling**
	다중 처리기 시스템의 CPU 스케줄링에 관한 한 가지 해결 방법은 마스터 서러(master server)라는 하나의 처리기가 모든 스케줄링 결정과 I/O 처리 그리고 다른 시스템의 활동을 취급하게 하는 것이다.
	이러한 **비대칭 다중 처리(asymmetric multiprocessing)** 은 오직 하나의 코어만 시스템 자료구조에 접근하여 자료 공유의 필요성을 배제하기 때문에 간단하다. 이 접근 방식의 단점은 마스터 서버가 전체 시스템 성능을 저하할 수 있는 병목이 된다는 점이다.
	**대칭 다중 처리(symmetric multi-processing, SMP)** 각 프로세스는 스스로 스케줄링을 할 수 있다. 각 프로세서의 스케줄러가 준비 큐를 검사하고 실행할 스레드를 선택하여 스케줄링이 진행된다. 이는 스케줄 대상이 되는 스레드를 관리하기 위한 두 가지 가능한 전략을 제공한다.
	1. 모든 스레드가 공통 준비 큐에 있을 수 있다.
	2. 각 프로세서는 자신만의 스레드 큐를 가질 수 있다.

	Windows, Linux 및 macOS와 Android, iOS의 모바일 시스템을 포함한 거의 모든 최신 운영체제는 SMP를 지원한다.
<br>

- **다중 코어 프로세서 Multicore Processors**
	SMP 시스템은 다수의 물리 처리기를 제공함으로서 다수의 프로세스가 병렬로 실행되게 한다. 그러나 현대 컴퓨터 하드웨어는 동일한 물리적인 칩 안에 여러 개의 처리 코어를 장착하여 **다중 코어 프로세서(Multicore processor)** 가 된다. 각 코어는 구조적인 상태를 유지하고 있어서 운영체제 입장에서는 개별적인 논리적 CPU처럼 보이게 된다.
	연구자들은 프로세서가 메모리에 접근할 때 데이터가 가용해지기를 기다리면서 많은 시간을 허비한다는 것을 발견하였다(메모리 스톨, memory stall). 이 상황은 최신 프로세서가 메모리보다 훨씬 빠른 속도로 작동하기 때문에 주로 발생한다. 메모리 스톨은 캐시 미스(캐시 메모리에 없는 데이터를 액세스하는 것)로 인해 발생할 수도 있다.
	이러한 상황을 해결하기 위해 하드웨어 설계는 다중 스레드 처리 코어를 구현하였다. 하나의 코어에 2개 이상의 하드웨어 스레드가 할당된다. 이렇게 하면 메모리를 기다리는 동안 하나의 하드웨어 스레드가 중단되면 코어가 다른 스레드로 전환될 수 있다. 이걸 **칩 다중 스레딩(chip multithreading, CMT)** 라고 한다.
	Intel 프로세서는 단일 하드웨어 코어에 여러 하드웨어 스레드를 할당하는 것을 설명하기 위해 **하이퍼-스레딩[동시 다중 스레딩(simultaneous multithreading, SMT)]** 라는 용어를 사용한다.
<br>

- **부하 균등화 Load Balancing**
	SMP 시스템에서 처리기가 하나 이상이라는 것을 최대한 활용하려면, 부하를 모든 처리기에 균등하게 배분하는 것이 매우 중요하다. **부하 균등화** 는 SMP 시스템의 모든 처리기 사이에 부하가 고르게 배분되도록 시도한다.
	부하 균등화를 위해서는 push 이주(migration) 와 pull 이주 방식의 두 가지 일반적인 접근법이 있다.
	Push 이주에서는 특정 태스크가 주기적으로 각 처리기의 부하를 검사하고 만일 불균형 상태로 밝혀지면 과부하인 처리기에서 쉬고 있거나 덜 바쁜 처리기로 스레드를 이동(또는 push)시킴으로서 부하를 분배한다.
	Pull 이주에서는 쉬고 있는 처리기가 바쁜 처리기를 기다리고 있는 프로세스를 pull할 때 일어난다.
	Push와 pull이주는 상호 배타적일 필요는 없으며 실제로는 부하 균등화 시스템에서 종종 병렬적으로 구현된다.
<br>

- **처리기 선호도 Processor Affinity**
	스레드에 의해 가장 최근에 접근된 데이터가 그 처리기의 캐시를 채우게 된다. 스레드에 의한 잇따른 메모리 접근은 캐시 메모리에서 만족한다(warm cache라고 함).
	만약 스레드가 다른 처리기로 이주한다면 첫 번째 프로세서의 캐시 메모리의 내용은 무효화 되어야 하며 두 번째 프로세서의 캐시는 다시 채워져야 한다.
	그 비용이 많이 들기 때문에 SMP를 지원하는 대부분의 운영체제는 스레드를 한 프로세서에서 다른 프로세서로 이주시키지 않고 대신 같은 프로세서에서 계속 실행시키면서 warm cache를 이용하려 한다. **이를 프로세서 선호도** 라 한다.
	흥미롭게도 부하 균등은 종종 프로세서 선호도의 이점을 상쇄한다. 스레드를 한 프로세서에서 다른 프로세서로 이동하여 부하를 균등하게 조정하면 캐시 메모리가 플러쉬 되기 때문에 이러한 이점이 사라진다.
<br>

- **이기종 다중 처리 Heterogeneous Multiprocessing**
	모바일 시스템에서는 현재 다중 코어 아키텍처가 채택되어 있지만 일부 시스템은 동일한 명령어 집합을 실행하지만 전력 소비를 유휴 수준으로 조정하는 기능을 포함하여 클록 속도 및 전력 관리 측면에서 차이가 나는 코어를 사용하여 설계되었다.

## 5.6 실시간 CPU 스케줄링 Real-Time CPU Scheduling
일반적으로 연성(sofr)실시간 시스템과 경성(hard) 실시간 시스템으로 구분한다.
**연성 실시간 시스템** 은 중요한 실시간 프로세스가 스케줄 되는 시점에 관해 아무런 보장을 하지 않는다. 연성 실시간 시스템은 오직 중요 프로세스가 그렇지 않은 프로세스들에 비해 우선권을 가진다는 것만 보장한다.
**경성 실시간 시스템** 은 더 엄격한 요구 조건을 만족시켜야한다. 태스크는 반드시 마감시간까지 서비스를 받아야 하며 마감시간이 지난 이후에 서비스를 받는 것은 서비스를 전혀 받지 않는 것과 동일한 결과를 낳는다.

- **지연시간 최소화 Minimizing Latency**
	시스템은 일반적으로 실시간으로 발생하는 이벤트를 기다린다. 이벤트가 발생하면, 시스템은 가능한 빨리 그에 응답을 하고 그에 맞는 동작을 수행하여야 한다.
	**이벤트 지연시간** 은 이벤트가 발생해서 그에 맞는 서비스가 수행될 때까지의 시간을 말한다. 다음의 두 가지 유형의 지연시간이 실시간 시스템의 성능을 좌우한다.
	1. 인터럽트 지연시간
	2. 디스패치 지연시간

	**인터럽트 지연시간** 은 CPU에 인터럽트가 발생한 시점부터 해당 인터럽트 처리 루틴이 시작하기까지의 시간을 말한다. 인터럽트 지연시간에 영향을 주는 요인 중 하나는 커널 데이터 구조체를 갱신하는 동안 인터럽트가 불능케 되는 시간이다.
	**디스패치 지연시간** 은 스케줄링 디스패처가 하나의 프로세스를 블록시키고 다른 프로세스를 시작하는 데까지 걸리는 시간을 말한다. CPU를 즉시 사용해야 하는 실시간 태스크가 있다면, 실시간 운영체제는 이 지연 시간을 최소화해야 한다.
	디스패치 지연시간의 **충돌 단계** 는 다음의 두 가지 요소로 구성되어 있다.
	1. 커널에서 동작하는 프로세스에 대한 선점
	2. 높은 우선순위의 프로세스가 필요한 자원을 낮은 우선순위 프로세스 자원이 방출.
<br>

- **우선순위 기반 스케줄링 Priority-Based Scheduling**
	실시간 운영체제에서 가장 중요한 기능은 실시간 프로세스에 CPU가 필요할 때 바로 응답을 해주는 것이다. 따라서 실시간 운영체제의 스케줄러는 선점을 이용한 우선순위 기반의 알고리즘을 지원해야만 한다.
<br>

- **Rate-Monotonic 스케줄링**
	Rate-monotonic 스케줄링 알고리즘은 선점 가능한 정적 우선순위 정책을 이용하여 주기 태스크들을 스케줄 한다. 낮은 우선순위의 프로세스가 실행 중이고 높은 우선순위의 프로세스가 실행 준비가 되면, 높은 우선순위의 프로세스가 낮은 우선순위의 프로세스를 선점한다.
	이 정책은 CPU를 더 자주 필요로 하는 태스크에 더 높은 우선순위를 주려는 원리에 기반을 두고 있다. 더욱이 rate-monotonic 스케줄링은 프로세스가 CPU를 차지한 사간은 각각의 CPU버스트 시간과 같다.
<br>

- **Earliest-Deadline-First 스케줄링**
	EDF 스케줄링 기법은 마감시간에 따라서 우선순위를 동적으로 부여한다. 마감시간이 빠를수록 우선순위는 높아지고, 늦을수록 낮아진다. EDF 정책에서는, 프로세스가 실행 가능하게 되면 자신의 마감시간을 시스템에 알려줘야 한다. 우선순위는 새로 실행 가능하게 된 프로세스의 마감시간에 맞춰서 다시 조정된다. 이 점이 우선순위가 고정되어 있는 rate-monotonic 스케줄링 기법과 다른 점이다.
	Rate-monotonic 알고리즘과는 달리 EDF 스케줄링 알고리즘은 프로세스들이 주기적일 필요도 없고, CPU 할당 시간도 상수 값으로 정해질 필요가 없다. 그러나 프로세스가 실행 가능해질 때 자신의 마감시간을 스케줄러에게 알려주어야 한다.
<br>

- **일정 비율의 몫 스케줄링 Proportionate Share Scheduling**
	일정 비율의 몫 스케줄러는 모든 응용들에 *T*개의 시간 몫을 할당하여 동작한다. 한 개의 응용이 *N*개의 시간 몫을 할당받으면 그 응용은 모든 프로세스 시간 중 *N/T*시간을 할당받게 된다.
	일정 비용의 몫 스케줄러는 응용이 시간 몫을 할당받는 것을 보장하는 승인 제어 정책과 함께 동작해야만 한다.
<br>

- **POSIX 실시간 스케줄링 POSIX Real-Time Scheduling**
<br>

## 5.8 알고리즘의 평가 Algorithm Evaluation

- **결정론적 모델링 Deterministic Modeling**
	평가 방법의 한 중요한 부류로 **분석적 평가(analytic evaluation)** 분석적 평가에서는 주어진 작업 부하에 대한 알고리즘의 성능을 평가하는 공식이나 값을 생성하기 위해 주어진 알고리즘과 시스템 작업 부하를 이용한다.
	결정론적 모델링 방식은 사전에 정의된 특정한 작업 부하를 받아들여 그 작업 부하에 대한 각 알고리즘의 성능을 정의한다.
<br>

- **큐잉 모델 Queueing Models**
<br>

- **모의 실험 Simulation**
<br>

- **구현 Implementation**
<br>

