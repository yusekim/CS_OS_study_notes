### 챕터 9요약
- 메모리는 최신 컴퓨터 시스템 작동의 중심이며 각각 고유한 주소를 가진 큰 바이트 배열로 구성된다.
- 각 프로세스에 주소 공간을 할당하는 한 가지 방법은 깆준 및 상한 레지스터를 사용하는 것이다. 기준 레지스터는 가장 작은 유효한 물리 메모리 주소를 저장하며 상한은 메모리 범위의 크기를 지정한다.
- 심볼릭 주소 참조를 실제 물리 주소에 바인딩하는 작업은 (1)컴파일, (2)적재 또는 (3)실행시간에 발생할 수 있다.
- CPU가 생성한 주소를 논리 주소라고 하며 메모리 관리 장치(MMU)가 메모리의 물리 주소로 변환한다.
- 메모리를 할당하는 한 가지 방법은 다양한 크기의 연속 메모리 파티션을 할당하는 것이다. 이러한 파티션은 세 가지 가능한 전략, 즉 (1) 최초 적합, (2) 최적 적합 및 (3) 최악 적합에 따라 할당될 수 있다.
- 최신 운영체제는 페이징을 사용하여 메모리를 관리한다. 이 과정에서 물리 메모리는 프레임이라는 고정 크기 블록으로, 논리 메모리는 페이지라는 같은 크기의 블록으로 나뉜다.
- 페이징을 사용하는 경우 논리 주소는 페이지 번호와 페이지 오프셋이라는 두 부분으로 나뉜다. 페이지 번호는 페이지를 저장하는 물리 메모리 프레임을 유지하는 프로세스별 페이지 테이블에 대한 인덱스 역할을 한다. 오프셋은 참조되는 프레임의 특정 위치이다.
- TLB(translation look-aside buffer)는 페이지 테이블의 하드웨어 캐시이다. 각 TLB 항목에는 페이지 번호와 상응하는 프레임을 저장한다.
- 페이징 시스템의 주소 변환에 TLB를 사용하려면 논리 주소에서 페이지 번호를 가져 와서 해당 페이지의 프레임이 TLB에 있는지 확인한다. 만약 그렇다면, 프레임은 TLB로부터 얻어진다. TLB에 프레임이 없으면 페이지 테이블에서 찾아야 한다.
- 계층적 페이징은 논리 주소를 여러 부분으로 나누고 각 단계는 서로 다른 페이지 테이블 수준을 나타낸다. 주소가 32비트 이상으로 확장됨에 따라 계층 레벨 수가 커질 수 있다. 이 문제를 해결하는 두 가지 전략은 해시 페이지 테이블과 역 페이지 테이블이다.
- 스와핑을 통해 시스템은 프로세스에 속하는 페이지를 디스크로 이동하여 다중 프로그래밍 정도를 높일 수 있다.
- Intel 32비트 아키텍처에는 두 가지 수준의 페이지 테이블이 있으며 4KB 또는 4 MB 페이지 크기를 지원한다. 이 아키텍처는 또한 페이지 주소 확장을 지원하므로 32비트 프로세서가 4 GB보다 큰 물리적 주소 공간에 액세스 할 수 있다. x86-64 및 ARMv9 아키텍처는 계층적 페이징을 사용하는 64비트 아키텍처이다.

### 이 장의 목표
- 논리 주소와 물리 주소의 차이점과 주소를 변환할 때 MMU(메모리 관리 장치)의 역할을 설명한다.
- 메모리를 연속적으로 할당하기 위해 최초, 최적, 최악 접합 전략을 적용한다.
- 내부 및 외부 단편화의 차이점을 설명한다.
- TLB (translation look-aside buffer)가 포함된 페이징 시스템에서 논리 주소를 물리 주소로 변환한다.
- 계층적 페이징, 해시 페이징 및 역 페이지 테이블을 설명한다.
- IA-32, x86-64 및 ARMv8 아키텍처의 주소 변환에 관해 설명한다.

## 9.1 배경
메모리는 각각 주소가 할당된 일련의 바이트들로 구성된다.
전형적인 명령어 실행은 먼저 메모리로부터 한 명령어를 가져오는 데서부터 시작된다. 그런 다음 명령어를 해독하고, 메모리에서 피연산자(operand)를 가져와 피연산자에 대해 명령어를 실행한 후에 계산 결과를 메모리에 다시 저장한다.

- **기본 하드웨어**
메인 메모리와 각 처리 코어에 내장된 레지스터들은 CPU가 직접 접근할 수 있는 유일한 범용 저장장치이다.
기계 명령어들은 메모리 주소만을 인수로 취하기 때문에(디스크 주소 X), 모든 실행되는 명령어와 데이터들을 CPU가 직접적으로 접근할 수 있는 메인 메모리와 레지스터에 있어야 한다.
각 CPU 코어에 내장된 레지스터들은 일반적으로 CPU 클록(clock)의 1사이클 내에 접근이 가능하다.
메인 메모리의 접근을 완료하기 위해서는 많은 CPU 클록 틱 사이클이 소요되며, 이 경우 CPU가 필요한 데이터가 없어 명령어 수행이 지연되는(stall) 현상이 발행하게 된다.
Stall 현상의 해결방법은 CPU와 메인 메모리 사이에(통상 빠른 접근을 위해 CPU 안에) 빠른 속도의 메모리(**캐시**, 1.5.5절)를 추가하는 것이다.
운영체제가 CPU와 메모리 간의 접근 중에 개입하게 되면 성능이 떨어지기 때문에 이러한 보호 기법은 반드시 하드웨어가 지원하여야 한다.
	- 각각의 프로세스가 독립된 메모리 공간을 가지도록 보장해야 한다. 그걸 위해서 특정 프로세스만 접근할 수 있는 합법적인(legal) 메모리 주소 영역을 설정하고, 프로세스가 그 영역만을 접근하도록 하는 것이 필요하다.(그림 9.1)
	**기준 레지스터**는 가장 작은 합법적인 물리 메모리 주소의 값을 저장하고, **상한 레지스터**는 주어진 영역의 크기를 저장한다. 예를 들어 기준 레지스터 값이 300040이고, 상한 레지스터의 값이 120900이라면 프로그램은 300040에서 420940까지의 모든 주소를 접근할 수 있다.
사용자 모드에서 수행되는 프로그램이 운영체제의 메모리 공간이나 다른 사용자 프로그램의 메모리 공간에 접근하면 운영체제는 치명적인 오류로 간주하고 트랩(trap)을 발생시킨다.
<br>
- **주소의 할당**
프로그램은 원래 이진 실행 파일 형태로 디스크에 저장되어 있다. 실행하려면 프로그램을 메모리로 가져와 프로세스 문맥(2.5절) 내에 배치해야 한다.
전통적으로 메모리 주소 공간에서 명령어와 데이터의 바인딩은 그 바인딩이 이루어지는 시점에 따라 다음과 같이 구분된다.
	- **컴파일 시간 바인딩**: 만일 프로세스가 메모리 내에 들어갈 위치를 컴파일 시간에 미리 알 수 있으면 컴파일러는 **절대코드**를 생성할 수 있다. 예를 들면 사용자 프로세스가 R번지로부터 시작한다는 것을 미리 알 수 있으면 컴파일러는 번역할 코드를 그 위치에서 시작해 나간다. 그러나 만일 이 위치가 변경되어야 한다면 이 코드는 재컴파일되어야 한다.
	- **적재 시간 바인딩**: 만일 프로세스가 메모리 내 어디로 올라오게 될지를 컴파일 시점에 알지 못하면 컴파일러는 일단 이진 코드를 **재배치 가능 코드**로 만들어야 한다. 이 경우 심볼과 진짜 번지수와의 바인딩은 프로그램이 메인 메모리로 실제로 적재되는 시간에 이루어지게 된다. 이렇게 만들어진 재배치 가능 코드는 시작 주소가 변경되면 아무 때나 사용자 코드를 다시 적재하기만 하면 된다.
	- **실행 시간 바인딩**: 만약 프로세스가 실행하는 중간에 메모리 내의 한 세그먼트ㅗㄹ부터 다른 세그먼트로 옮겨질 수 있다면 우리는 바인딩이 실행 시간까지 허용되었다고 이야기한다. 이러한 것이 가능해지려면 특별한 하드웨어를 이용해야 한다.
<br>

- **논리 대 물리 주소 공간**
CPU가 생성하는 주소를 일반적으로 **논리 주소(logical address)**라 하고, 메모리가 취급하게 되는 주소[**메모리 주소 레지스터(MAR)**]는 일반적으로 **물리 주소(physical address)**라 한다.
컴파일 또는 적재 시에 주소를 바인딩하면 논리 주소와 물리 주소가 같다. 그러나 실행 시간 바인딩 기법에서는 논리, 물리 주소가 다르다. 이 경우 논리 주소를 **가상 주소(virtual adress)**라 한다.
프로그램의 실행 중에는 이와 같은 가상 주소를 물리 주소로 바꾸어줘야 하는데 이 변환(mapping)작업은 하드웨어 장치인 **메모리 관리 장치(memory management unit, MMU)**에 의해 실행된다.
<br>

- **동적 적재**
메모리 공간의 더 효율적인 이용을 위해서는 **동적 적재(dynamic loading)**를 해야 한다. 각 루틴은 실제 호출되기 전까지는 메모리에 올라오지 않고 재배치 가능한 상태로 디스크에서 대기하고 있다.
먼제 main프로그램이 메모리에 올라와 실행된다. 이 루틴이 다른 루팅을 호출시, 해당 루틴이 메모리에 적재되어 있는지 조사하고, 적재가 되어 있지 않을 시 재배치 가능 연결 적재기(relocatable linking loader)가 불려 루틴을 메모리로 가져오고, 테이블에 기록해 둔다.
동적 적재의 장점은 루틴이 필요한 경우에만 적재된다는 것이다. 이러한 구조는 오류 처리 루틴과 같은 매우 적은 확률로 발생하면서도 실행할 코드가 많은 경우에 유용하다. 동적 적재는 운영체제로부터 특별한 지원이 필요하지 않다.

- **동적 연결 및 공유 라이브러리**
**동적 연결 라이브러리(DLL)**는 사용자 프로그램이 실행될 때, 사용자 프로그램에 연결되는 시스템 라이브러리이다. 주로 표준 C언어 라이브러리와 같은 시스템 라이브러리에 사용된다.
DLL은 메모리 공간 낭비를 줄일 수 있고, 해당 라이브러리를 여러 프로세스간 공유할 수 있어 메인 메모리에 DLL인스턴스가 하나만 있을 수 있다. DLL은 공유 라이브러리라고도 하며 여러 운영체제 시스템에서 광범위하게 사용된다.
프로그램이 동적 라이브러리에 있는 루틴을 참조하면 로더는 DLL을 찾아 필요한 경우 메모리에 적재한다. 그 후 동적 라이브러리의 함수를 참조하는 주소를 DLL이 저장된 메모리의 위치로 조정한다.
동적 적재와 달리, 동적 연결과 공유 라이브러리는 운영체제의 도움이 필요하다. 운영체제는 기억 공간에 루틴이 있는지 검사하고 여러 프로세스가 같은 메모리 주소를 공용할 수 있도록 해준다.
<br>

## 9.2 연속 메모리 할당
초기 메모리 할당 방법의 하나인 연속 메모리 할당에 관한 절이다.
메모리는 일반적으로 운영체제를 위한 부분, 사용자 프로세스를 위한 부분 두 개로 나뉜다. 일반적으로 여러 사용자 프로세스가 동시에 메모리에 상주하기를 원한다.
연속적인 메모리 할당에서 각 프로세스는 다음 프로세스가 적재된 영역과 인접한 하나의 메모리 영역에 적재된다.

- **메모리 보호**
재배치/상한 레지스터와 MMU를 통해 프로세스가 자신이 소유하지 않은 메모리를 접근할 수 없게 강제할 수 있다.
<br>

- **메모리 할당**
메모리를 할당하는 가장 간단한 방법 중 하나는 프로세스를 메모리의 가변 크기 파티션에 할당하는 것이다.
각 파티션에는 정확히 하나의 프로세스만 적재될 수 있다(**가변 파티션**). 운영체제는 사용 가능한 메모리 부분과 사용 중인 부분을 나타내는 테이블을 유지한다.
프로세스가 시스템에 들어오면, 운영체제는 각 프로세스가 메모리를 얼마나 요구하며, 또 사용 가능한 메모리 공간이 어디에 얼마나 있는지를 고려하여 공간을 할당한다. 이후로는 CPU를 할당받기 위해 경쟁한다.
**hole**(사용 가능한 메모리 블록)을 찾았는데 요청한 메모리 크기보다 크면 두 조각으로 나눠 하나는 프로세스에 할당하고, 나머지 블록은 hole집합으로 되돌아간다.
이 새로운 hole이 다른 hole과 인접해 있다면 두 개의 블록을 합쳐 한 개의 큰 hole로 만든다.
동적 메모리 할당 문제(dynamic storage allocation problem): 일련의 가용공간-리스트로부터 크기 n-바이트 블록을 요구하는 것을 어떻게 만족시켜 줄 것이냐를 결정하는 문제이다.
	- **최초 적합**: 첫 번째 사용 가능한 가용 공간을 할당한다.
	- **최적 적합**: 사용 가능한 공간 중에서 가장 작은 것을 택한다.
	- **최악 적합**: 가장 큰 가용을 택한다.
<br>

- **단편화**
**외부 단편화(external fragmentation)** 은 할당되어 남은 메모리 공간들의 총합은 새 프로세스를 할당하기의 충분하지만, 너무 작은 조각들로 여러 곳에 분산되어 있을 때 발생한다.
**내부 단편화(internal fragmentation)** 은 프로세스에 할당된 공간이 프로세스가 필요한 공간보다 커서 남게 되는 메모리가 존재하게 되는 문제이다.
메모리의 모든 내용을 한곳으로 몰고 모든 가용 공간을 하나로 합치는 **압축(compaction)** 방법도 있지만, 재배치가 어셈블 또는 적재 시에 정적으로 행해진다면, 압축은 행해질 수 없다.
또 다른 방법은 **페이징**으로, 한 프로세스의 논리 주소 공간을 여러 개의 비연속적인 공간으로 나누어 필요한 크기의 공간이 가용해지는 경우 물리 메모리를 프로세스에 할당하는 방법이다.
<br>

## 9.3 페이징

- **기본 방법**
물리 메모리는 **프레임(frame)** 이라 불리는 같은 크기 블록으로 이루어진다. 논리 메모리는 **페이지(page)** 라 불리는 같은 크기의 블록으로 나누어진다.
CPU에서 나오는 모든 주소는 **페이지 번호(p)** 와 **페이지 오프셋(d: offset)** 두 개의 부분으로 나누어진다.
페이지 번호는 **프로세스 페이지 테이블(page table)** 을 액세스할 때 사용된다. 페이지 테이블은 물리 메모리의 각 프레임의 시작 주소를 저장하고 있으며 오프셋은 참조되는 프레임 안에서의 위치이다.
프레임의 시작 주소와 페이지 오프셋이 결합하여 물리 메모리 주소가 된다.
MMU가 CPU의 논리 주소를 물리 주소로 변환하는 과정
	1. 페이지 번호 p를 추출하여 페이지 테이블의 인덱스로 사용한다.
	2. 페이지 테이블에서 해당 프레임 번호 f를 추출한다.
	3. 논리 주소의 페이지 번호 p를 프레임 번호 f로 바꾼다.

	논리 주소 공간의 크기가 2^m이고 페이지 크기가 2^n바이트인 경우 논리 주소의 상위 m - n 비트는 페이지 번호를 지정하고 n 하위 비트는 페이지 오프셋을 지정한다(그림 9.8 ~ 9.10).
	페이징 기법을 사용하면 외부 단편화는 해결할 수 있지만, 내부 단편화가 발생한다. 만약 프로세스가 페이지 경계와 일치하지 않는 크기의 메모리를 요구하면, 마지막 페이지 프레임은 전부 할당되지 않는다.
	운영체제는 물리 메모리를 관리하기 때문에 물리 메모리의 자세한 할당에 대해 파악해야 한다. 이런 정보는 일반적으로 **프레임 테이블(frame table)** 이라는 자료구조에 위치해 있다.
	프레임 테이블은 각 프레임당 하나의 항목을 가지고 있으며, 프레임의 가용 여부와 가용된 프로세스의 세부 정보(프로세스의 어느 페이지에 할당되었는지 등)가 기록되어 있다.
<br>

- **하드웨어 지원**
대부분의 컴퓨터는 페이지 테이블을 메인 메모리에 저장하고 **페이지 테이블 기준 레지스터(page-table base register, PTBR)** 로 하여금 페이지 테이블을 가리키도록 한다.
다른 페이지 테이블을 사용하려면 해당 레지스터만을 변화시키면 되기 때문에 문맥 교환 시간을 줄일 수 있다.
<br>

- **Translation Look-Aside Buffer(TLB)**
메인 메모리에 페이지 테이블을 저장하면 문맥 교한 속도가 빨라지지만 메모리 액세스 시간이 느려질 수도 있다.
이를 해결하기 위해 **TLB** 라고 불리는 특수한 소형 하드웨어 캐시가 사용된다. TLB는 매우 빠른 연관 메모리(associative memory)로 구성되어 있다.
TLB내 각 항목은 key와 value로 구성된다. TLB에 페이지를 찾아달라고 요청이 들어오면 찾고자 하는 페이지를 동시에 여러 개의 내부 키(페이지 번호)와 비교를 해서 발견 시(TLB hit) 알려준다.
TLB는 페이지 테이블의 일부분만을 저장한다. CPU가 논리 주소를 생성되면 MMU는 해당 페이지 번호가 TLB에 있는지 확인한다. 페이지 번호가 TLB에 없으면(TLB miss) 기존의 메모리 액세스 방식을 이용한다.
어떤 TLB는 각 항목에 ASIDs(address-space identifiers)를 저장하기도 한다. ASID는 그 TLB항목이 어느 프로세스에 속한 것이지를 알려주며 그 프로세스의 정보를 보호하기 위해 사용된다.
<br>

- **보호**
페이징 환경에서 메모리 보호는 각 페이지에 붙어 있는 **보호 비트(protection bits)** 에 의해 구현된다.
각 비트는 이 페이지가 읽고 쓰기 또는 읽기 전용(read-only)임을 정의할 수 있다.
페이지 테이블의 각 엔트리에는 **유효/무효(vaild/invaild)** 라는 하나의 비트가 더 있다.
이 비트가 유효하면 관련된 페이지가 프로세스의 합법적인 페이지임을 나타내며, 그렇지 않을 경우 그 페이지는 프로세스의 논리 주소 공간에 속하지 않는다는 것을 나타낸다.
운영체제는 이 비트를 이용해 그 페이지에 대한 접근 허용 여부를 결정할 수 있다.
<br>

- **공유 페이지**
페이징의 장점은 공통의 코드를 **공유** 할 수 있다는 점이다.
코드가 재진입 코드(Reentrant Code, 여러 프로세스나 스레드에서 동시에 실행될 수 있는 코드)인 경우 실행중에는 절대 변경되지 않는다는 점을 보장해 여러 프로세스가 동일한 코드를 동시에 실행할 수 있다.
<br>

## 9.4 페이지 테이블의 구조

- **계층적 페이징**
현대 컴퓨터는 매우 큰 주소 공간(2^32 ~ 2^64). 이러한 환경에서는 페이지 테이블도 상당히 커진다. 이렇게 커진 테이블을 할당하는 방법 중 하나는 페이지 테이블을 여러 개의 작은 조각으로 나누는 것이다.
2단계 페이징 기법(two-level paging schemem)은 페이지 테이블 자체각 다시 페이징되게 하는 것이다(그림 9.15). 하지만 64비트 구조에서는 부적합하다.
<br>

- **해시 페이지 테이블**
주소 공간이 32비트보다 커지면 가상 주소를 해시로 사용하는 **해시 페이지 테이블** 을 많이 쓴다.
해시 페이지 테이블의 각 항목은 연결 리스트를 가지고 있다. 이곳에는 충돌을 일으켜서 모두 이곳으로 해시되는 원소들이 매달리게 된다.
각 원소는 (1) 가상 페이지 번호 (2) 사상되는 페이지 프레임 번호 (3) 연결 리스트상의 다음 원소 포인터.
64비트 시스템에서는 **클러스터 페이지 테이블** 사용하여 더욱 개선되었다. 해시 페이지 테이블의 각 항목이 한 개의 페이지만 가르키는 반면, 클러스터 페이지 테이블의 각 항목은 여러 페이지를 가리킨다.

- **역 페이지 테이블**
각 페이지 테이블 항목의 개수가 많을 경우 물리 메모리의 사용을 추적하기 위해 많은 양의 물리 메모리를 소비해야하는 문제점이 있다.
이 문제를 해결하는 한 방법으로 **역 페이지 테이블(inverted page table)** 이 있다.
역 페이지 테이블에서는 메모리 프레임마다 한 항목씩을 할당한다. 각 항목은 페이지 주소, 페이지를 소유하고 있는 프로세스의 ID를 가지고 있다.(그림 9.18)
이 방법은 물리 프레임에 대응되는 항목만 테이블에 저장하기 때문에 메모리에서 훨씬 작은 공간을 점유한다. 하지만 주소변환 시간이 더 오래 걸릴 수 있다. 이를 해결하기 위해 해시 테이블을 사용한다.
<br>

- **Oracle SPARC Solaris**
<br>

## 9.4 스와핑
프로세스 또는 프로세스의 일부분은 실행 중에 임시로 **백업 저장장치(backing store)** 로 내보내어 졌다가 실행을 계속하기 위해 다시 메모리로 되돌아 올 수 있다.
모든 프로세스의 물리 주소 공간 크기의 총합이 시스템의 실제 물리 메모리 크기보다 큰 경우에도 스와핑을 이용하면 동시에 실행하는 것이 가능하여 다중 프로그래밍의 정도를 증가시킨다.

- **기본 스와핑**
메인 메모리와 백업 저장장치 간에 전체 프로세스를 이동한다. 백업 저장장치는 일반적으로 빠른 보조저장장치이다.

- **페이징에서의 스와핑**

