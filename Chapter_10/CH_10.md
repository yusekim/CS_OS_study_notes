### 챕터 10요약
- 가상 메모리는 물리 메모리를 매우 큰 균일한 저장장소 배열로 추상화한다.
- 가상 메모리의 이점은 다믕과 같다. 1. 프로그램이 물리 메모리보다 클 수 있음, 2. 프로그램 전체가 메모리에 있을 필요는 없음, 3. 프로세스가 메모리를 공유할 수 있음 및 4. 프로세스를 보다 효율적으로 생성할 수 있다.
- 요구 페이징은 프로그램 실행 중 페이지가 필요할 때만 페이지를 적재하는 기법이다. 따라서 절대로 요구되지 않은 페이지는 메모리에 적재되지 않는다.
- 현재 메모리에 없는 페이지에 액세스하면 페이지 폴트가 발생한다. 페이지는 백업 저장장치에서 메모리의 가용 페이지 프레임으로 가져와야 한다.
- 쓰기 시 복사를 통해 자식 프로세스는 부모 프로세스와 동일한 주소 공간을 공유할 수 있다. 자식 프로세스나 부모 프로세스가 페이지를 수정하면 페이지의 복사본이 만들어진다.
- 사용 가능한 메모리가 부족하면 페이지 교체 알고리즘이 메모리에 존재하는 기존 페이지를 선택하여 새 페이지로 바꾼다. 페이지 교체 알고리즘에는 FIFO, 최적 및 LRU가 포함된다. 순수한 LRU알고리즘은 구현하기에 비실용적이며 대부분의 시스템은 대신 LRU 근사 알고리즘을 사용한다.
- 전역 페이지 교체 알고리즘은 시스템의 모든 프로세스에서 교체할 페이지를 선택하고 지역 페이지 교체 알고리즘은 폴트를 발생시킨 프로세스에서 페이지를 선택한다.
- 스래싱은 시스템이 실행보다 페이징하는 데 더 많은 시간을 소비할 때 발생한다.
- 지역성은 함께 사용되는 일련의 페이지를 나타낸다. 프로세스가 실행되면 하나의 지역성에서 다른 지역성으로 이동한다. 작업 집합은 지역성에 기반을 두며 프로세스에서 현재 사용 중인 페이지 집합으로 정의된다.
- 메모리 압축은 여러 페이지를 하나의 페이지로 압축하는 메모리 관리 기법이다. 압축 메모리는 페이징의 대안이며 페이징을 지원하지 않는 모바일 시스템에서 사용된다.
- 커널 메모리는 사용자 모드 프로세스와 다르게 할당된다. 다양한 크기의 연속된 청크로 할당된다. 커널 메모리에 대한 두 가지 일반적인 기법은 1. 버디 시스템과 2. 슬랩 할당이다.
- TLB Reach는 TLB에서 액세스 할 수 있는 메모리 양을 나타내며 TLB의 항목 수엥 페이지 크기를 곱한 값과 같다. TLB reach를 늘리는 한 가지 기술은 페이지 크기를 늘리는 것이다.
- Linux, Windows 및 Solaris는 다른 기능 중에서도 요구 페이징 및 COW(copy-on-write)를 사용하여 가상 메모리를 유사하게 관리한다. 또한 각 시스템은 클록 알고리즘으로 알려진 LRU 근사 변형을 사용한다.

### 이 장의 목표
- 가상 메모리를 정의하고 그 이점을 설명한다.
- 요구 페이징을 사용하여 페이지가 메모리에 적재되는 방법을 설명한다.
- Linux, Windows 10 및 Solaris가 가상 메모리를 관리하는 방법을 설명한다.
- C 프로그래밍 언어로 가상 메모리 관리자 시뮬레이션을 설계한다

## 10.1 배경
프로그램 전체가 한꺼번에 메모리에 늘 올라와야하지는 않다..
- 잘 발생하지 않는 오류 상황을 처리하는 코드들은 거의 실행되지 않는다.
- 배열(arrays) 리스트(lists) 테이블(table)등은 필요 이상으로 많은 공간을 점유할 수도 있다.
- 프로그램 내 어떤 옵션(option)이나 기능들을 거의 사용되지 않는다, 또한 전체 프로그램이 필요한 경우에도 그 프로그램의 모든 부분이 모두 동시에 요구되지 않을 수 있다.

만약 프로그램을 일부분만 메모리에 올려놓고 실행할 수 있다면 다음과 같은 많은 이점이 있다..
- 프로그램은 물리 메모리 크기에 의해 더는 제약받지 않는다. 사용자들은 매우 큰 가상 주소 공간을 가정하고 프로그램을 만들 수 있기 때문에 프로그래밍 작업이 간단해진다.
- 각 프로그램이 더 작은 메모리를 차지하므로 더 많은 프로그램을 동시에 수행할 수 있다. 이에 따라 응답 시간(response time)은 늘어나지 않으면서도 CPU 이용률(utilization)과 처리율(throughput)이 높아진다.
- 프로그램을 메모리에 올리고 스왑(swap)하는데 필요한 I/O회수가 줄어들기 때문에 프로그램이 보다 빨리 실행된다

**가상 메모리**는 실제의 물리 메모리 개념과 개발자의 논리 메모리 개념을 분리한 것이다(그림 10.1).
한 프로세스의 **가상 주소 공간**은 그 프로세스가 메모리에 저장되는 논리적인 모습(view)를 말한다(그림 10.2).
*힙(heap)* 은 동적 할당 메모리를 사용함에 따라 주소 공간상에서 위쪽으로 확장된다. 비슷한 방식으로 *스택(stack)* 은 함수 호출을 거듭함에 따라 주소 공간상에서 아래쪽으로 확장된다.
힙과 스택 사이의 공백도 가상 주소 공간의 일부이지만, 힙 또는 스택이 확장되어야만 실제 물리 페이지를 요구하게 될 것이다.
공백을 포함하는 가상 주소 공간을 *성긴(sparse)* 주소 공간이라 한다. 성긴 주소 공간의 공백은 스택이나 힙 세그먼트가 확장될 때 사용되거나 프로그램 실행 중 동적으로 라이브러리를 링크할 필요가 있을 때 사용된다.
가상 메모리는 또한 페이지 공유를 통해 파일이나 메모리가 둘 또는 그 이상의 프로세스들에 의해 공유되는 것을 가능하게 해주는데, 여기서 오는 장점은 다음과 같다.
- 표준 C 라이브러리와 같은 시스템 라이브러리가 여러 프로세스들에 공유될 수 있다. 각 프로세스는 라이브러리가 자신의 가상 주소 공간 일부라고 생각하지만, 실제로는 라이브러리가 존재하는 물리 메모리 페이지들은 모든 프로세스에 공유되고 있다(일반적으로 읽기만이 허용되는 상태).
- 프로세스들이 메모리를 공유할 수 있다. 가상 메모리는 한 프로세스가 다른 프로세스와 공유할 수 있는 영역을 만들 수 있도록 해 준다.
- 페이지는 fork() 시스템 콜을 통한 프로세스 생성 과정 중에 공유될 수 있기 때문에 프로세스 생성 속도를 높일 수 있다.
<br>

## 10.2 요구 페이징
**요구 페이징(demand paging)** 전략은, 프로그램 실행시 필요한 페이지만 메모리로 적재하는 것이다. 따라서 접근되지 않은 페이지는 물리 메모리로 적재되지 않는다.
- **기본 개념**
결과적으로 프로세스가 실행되는 동안 일부 페이지는 메모리에 있고 일부 페이지는 보조저장장치에 있다. 이 둘을 구별하기 위해 9.3.3절에서 사용한 유효/무효(valid-invaild) 비트 기법이 사용될 수 있다(그림 10.4).
만일 프로세스가 메모리에 올라와 있지 않은 페이지에 접근하려 하면 **페이지 폴트 트랩(page-fault trap)** 을 발생시킨다(그림 10.5).
페이지 폴트는 다음과 같이 처리된다.
	1. 프로세스에 대한 내부 테이블(internal table)[일반적으로 프로세스 제어 블록(PCB)와 함께 유지]을 검사해 해당 메모리 참조(reference)가 유효한지를 알아낸다.
	2. 무효한 페이지에 대한 참조라면 프로세스는 중단된다. 유효한 참조이고, 	페이지가 아직 메모리에 올라오지 않았다면, 그것을 보조기억장치로부터 가져와야 한다.
	3. 빈 공간(가용 프레임 free frame)을 찾는다.
	4. 보조저장장치에 새로이 할당된 프레임으로 해당 페이지를 읽어 들이도록 요청한다.
	5. 보조저장장치 읽기가 끝나면, 이 페이지가 이제는 메모리에 있다는 것을 알리기 위해 페이지 테이블을 갱신하며, 프로세스가 유지하고 있는 내부 테이블을 수정한다.
	6. 트랩에 의해 중단되었던 명령어를 다시 수행한다.

일단 필요한 모든 페이지가 적재되고 나면 더 폴트가 발생하지는 않는다. 이것이 **순수 요구 페이징(pure demand paging)**, 어떤 페이지가 필요해지기 전까지 결코 그 페이지를 메모리로 적재하지 않는 방법이다. 프로그램들은 한 명령어에서도 여러 개의 페이지 폴트를 일으킬 수도 있지만(이 경우 시스템 성능의 저하를 초래할 수 있다.). 다행히 이런 경우는 거의 발생하지 않는다.
10.6.1절에 기술된 바와 같이 **참조의 지역성(locality of reference)** 라고 불리는, 프로그램의 어느 한 특정 작은 부분만 한동안 집중적으로 참조하는 성질 덕에 요구 페이징은 만족할 만한 성능을 보인다. 요구 페이징을 지원하기 위해 필요한 하드웨어는 페이징과 스와핑을 위한 하드웨어와 동일하다.
- *페이지 테이블*: 보호 비트(protection bit)들 특별한 값 또는 유효/무효 비트를 통해 특정 항목을 무효로 설정할 수 있어야 한다.
- *보조저장장치(secondary memory)*: 메인 메모리에 없는 모든 페이지를 가지고 있다. 보통은 고성능의 디스크 또는 NVM 장치이다(스왑 장치라고도 한다).
<br>

- **가용 프레임 리스트**
페이지 폴트를 해결하기 위해 대부분의 운영체제는 이러한 요청을 충족시키기 위해 사용하기 위한 가용 프레임의 풀인 **가용 프레임 리스트**를 유지한다(그림 10.6).
시스템이 시작되면 모든 가용 메모리가 가용 프레임 리스트에 넣어진다. 가용 프레임이 요청되면(요구 페이징 등) 가용 프레임 리스트의 크기가 줄어든다.
<br>

- **요구 페이징의 성능**
요구 페이지 메모리에 대한 **실질 접근 시간**을 계산하기 위해 페이지 폴트의 처리 수순을 알아보자
1. 운영체제에 트랩을 요청한다.
2. 레지스터들과 프로세스 상태를 저장한다.
3. 인터럽트 원인이 페이지 폴트임을 알아낸다.
4. 페이지 참조가 유효한지 확인하고, 보조저장장치에 있는 페이지의 위치를 알아낸다.
5. 저장장치에 가용 프레임으로의 읽기 요구를 낸다
	1. 읽기 차례가 돌아오기까지 대기 큐에서 기다린다.
	2. 디스크에서 찾는(seek) 시간과 회전 지연 시간 동안 기다린다.
	3. 가용 프레임으로 페이지 전송을 시작한다.
6. 기다리는 동안엥 CPU 코어는 다른 사용자에게 할당된다.
7. 저장장치가 다 읽었다고 인터럽트를 건다(I/O 완료).
8. 다른 프로세스의 레지스터들과 프로세스 상태를 저장한다(6단계가 실행되었을 경우).
9. 인터럽트가 보조저장장치로부터 왔다는 것을 알아낸다.
10. 새 페이지가 메모리로 올라왔다는 것을 페이지 테이블과 다른 테이블들에 기록한다.
11. CPU코어가 자기 체례로 오기까지 다시 기다린다.
12. CPU 차례가 오면 위에서 저장시켜 두었던 레지스터들, 프로세스 상태, 새로운 페이지 테이블을 복원시키고 인터럽트 되었던 명령어를 다시 실행한다.

어떤 경우에도, 페이지 폴트 처리 시간은 **1.인터럽트의 처리, 2.페이지 읽기, 3.프로세스 재시작** 3개의 주요 작업 요소로 이루어져 있다.

## 10.3 쓰기 시 복사
`fork()`시스템 콜을 통해 프로세스를 생성할 때는 페이지 공유와 비슷한 기법으로 첫 요구 페이징조차 생략하는 것이 가능하다.
`fork()`는 부모 프로세스와 똑같은 자식 프로세스를 만들어 준다. 그렇지만 대부분의 자식은 만들어지마자 곧 `exec()`시스템 콜을 불러 부모로부터 복사해온 페이지들을 쓸모없게 한다.
그래서 부모의 페이지들을 다 복사해오는 대신 **쓰기 시 복사(copy-on-write)** 방식을 사용할 수 있다. 이 방식에서는 자식 프로세스가 시작할 때 부모의 페이지를 당분간 함께 사용하도록 한다.
Linux, macOS 및 BSD UNIX를 포함한 일부 운영체제들은 `vfork()(virtual memory fork)`라는 시스템 콜을 제공하고 있다.
`vfork()`를 하면 부모 프로세스는 보류되고 자식이 부모의 주소 공간을 사용하게 된다. `vfork()`는 자식이 만들어지자마자 `exec()`를 하는 경우를 위해 만들어졌다. 페이지가 전혀 복사되지 않기 때문에 매우 효율적이며 UNIX 명령어 해석기인 shell 구현 시에도 사용한다.
<br>

## 10.4 페이지 교체
전체 10페이지 중 실제 5페이지만을 사용하는 프로세스가 있다면, 요구 페이징을 통해 전혀 사용되지 않을 5페이지를 적재하는데 필요한 I/O를 피할 수 있다.
다중 프로그래밍 정도를 더 올리면, **메모리 과할당(over-allocating)** 이 발생한다(특정 상황에 프로세스들이 페이지를 더 요구해 가용 가능 페이지가 부족한 경우).
더욱이 시스템 메모리는 프로그램 페이지 말고도 많은 영역에서 메모리가 사용된다.
이 시점에서 운영체제는 몇 가지 선택을 할 수 있다. 프로세스를 종료하거나 표준 스와핑을 통해 프로세스를 스왑아웃 하여 모든 프레임을 비우고 다중 프로그래밍 정도를 줄일 수 있다.
그러나 위의 방법들은 메모리와 스왑 공간 사이에 전체 프로세스를 복사하는 오버헤드로 인해 대부분의 운영체제에서 표준 스와핑이 더는 사용되지 않는다.
대부분의 운영체제는 이제 이 절의 나머지 부분에서 자세히 설명하는 기법인 페이지 스와핑과 페이지 교체를 결합한다.

- **기본적인 페이지 교체**
만약 빈 프레임이 없다면 현재 사용되고 있지 않는 프레임을 찾아서 그것을 비워버린다. 그 프레임의 내용을 스왑 공간에 쓰고 그 페이지가 메모리에 이제는 존재하지 않는다는 것을 나타내기 위해, 페이지 테이블(모든 다른 테이블들)을 변화시킴으로써 프레임을 비워 있게 한다(그림 10.10). 페이지 폴트 서비스 루틴이 페이지 교체를 포함하여 다음과 같이 수정되어야 한다.
1. 보조저장장치에서 필요한 페이지의 위치를 알아낸다.
2. 빈 페이지 프레임을 찾는다.
	1. 비어있는 프레임이 있다면 그것을 사용한다.
	2. 비어있는 프레임이 없다면 *희생될(victim)* 프레임을 선정하기 위하여 페이지 교체 알고리즘을 가동시킨다.
	3. 희생될 페이지를 보조저장장치에 기록하고(필요한 경우), 관련 테이블을 수정한다.
3. 빼앗은 프레임에 새 페이지를 읽어오고 테이블을 수정한다.
4. 페이지 폴트가 발생한 지점에서부터 프로세스를 계속한다.
빈 프레임이 없는 경우에는 **디스크를 두번(프레임을 비울 때/읽어들일 때) 접근**해야 한다. 이러한 상황에서는 **페이지 폴트 처리 시간(page fault service time)** 이 2배 소요되며 그에 따라 실질 접근 시간도 증가한다.
이러한 오버헤드는 **변경 비트(modify bit/dirty bit)** 를 사용해 감소시킬 수 있다. 각 페이지나 프레임은 그것과 관련된 변경 비트를 하드웨어에 가지게 된다. 변경 비트는 CPU가 페이지 내의 어떤 바이트라도 쓰게 되면 페이지가 변경되었음을 나타내기 위해 설정된다.
요구 페이징 시스템은 **프레임 할당(frame-allocation)알고리즘**과 **페이지 교체(page-replacement)알고리즘** 두 문제를 해결해야 한다.
여러 프로세스가 존재하는 경우 각 프로세스에 얼마나 많은 프레임을 할당해야 할지 결정해야 한다. 또 페이지 교체가 필요할 때마다 어떤 페이지를 교체해야 할지 결정해야 한다.

- **FIFO 페이지 교체**
가장 간단한 페이지 교체 알고리즘으로, 메모리에 올라온지 가장 오래된 페이지를 내쫒는다. 이해하기 쉽고 구현도 쉽지만 성능이 항상 좋지는 않다.
	> Belady의 모순(Belady's anomaly): 프로세스에 프레임을 더 주었는데 오히려 페이지 폴트율은 더 **증가**하게 되는 현상.

- **최적 페이지 교체**
Belady의 모순이 가져온 결과중 하나는 **최적 교체 정책** 에 대한 탐색이다. 그러한 정책은 존재했고 OPT또는 MIN으로 불렸다.
안타깝게도 이 알고리즘은 프로세스가 앞으로 메모리를 어떻게 참조할 것인지를 미리 알아야 하기 때문에 구현이 어렵다.

- **LRU 페이지 교체**
최근의 과거를 가까운 미래의 근사치로 본다면 가장 오랜 기간 동안 *사용되지 않은* 페이지를 교체할 수 있다. 이 기법이 **least-recently-used (LRU) 알고리즘**이다.
LRU 페이지 교체 알고리즘은 하드웨어의 지원이 필요하다. 프레임들을 최근 사용된 시간 순서로 파악할 수 있어야 하기 때문이다. 두 가지의 구현 방법이 있다.
	- 계수기(counter): 각 페이지 항목마다 사용 시간 필드를 넣고 CPU에 논리적인 시계나 계수기를 추가한다. 각 페이지의 마지막 참조 시간을 알 수 있게 되면 시간 값이 가장 작은 페이지가 교체된다. 이 기법은 LRU페이지를 찾기 위해 페이지 테이블을 탐색하여야 하며, 메모리 참조 때마다 메모리 쓰기 작업을 필요로 한다.
	- 스택(stack): 페이지가 참조될 때마다 페이지 번호는 스택 중간에서 제거되어 스택 꼭대기(top)에 놓이게 된다. 이 방식을 적용하면 top에는 항상 최근에 사용된 페이지가 위치하고, bottom은 가장 오랫동안 이용되지 않은 페이지가 위치하게 된다. 매 갱신 시에는 약간 더 오버헤드가 크지만 교체갈 일어날 경우 페이지를 탐색할 필요가 없게 된다.

- **LRU 근사 페이지 교체**
많은 시스템은 참조 비트(reference bit)를 지원한다는 점에서 착안, 프로세스가 실행되면서 참조되는 페이지의 참조 비트는 하드웨어가 1로 세팅한다. 일정 시간 뒤에 어떤 페이지가 사용되었는지 여부를 알 수 있다.
	- 부가적 참조 비트 알고리즘: 일정한 간격마다 참조 비트들을 기록함으로서 추가적인 선후 관계 정보를 얻을 수 있다.
	- 2차 기회 알고리즘: FIFO에서 응용되었다. 페이지가 선택될 때마다 참조 비트를 확인해 0이면 페이지를 교체하고 1이면 다시 한번 기회를 주고 다음 FIFO페이지로 넘어간다. 순환 큐를 이용하여 2차 기회 알고리즘을 구현할 수 있다(그림 10.17).
	- 개선된 2차 기회 알고리즘: 변경 비트까지 2개의 비트를 조합하면 네 가지의 등급으로 나눌 수 있다.
		1. 00: 최근에 사용되지도 변경되지도 않은 경우 - 교체하기에 가장 좋은 페이지
		2. 01: 최근에 사용되지는 않았지만 변경은 된 경우 - 해당 페이지는 뺏어 오려면 디스크에 내용을 기록해야 하기 때문에 교체에 적합하지 않다.
		3. 10: 최근에 사용은 되었으나 변경은 되지 않은 경우 - 이 페이지는 곧 다시 사용될 가능성이 높다.
		4. 11: 최근에 사용도 되었고 변경도 된 경우 - 곧 다시 사용될 것이며 뺏으려면 디스크에 그 내용을 먼저 기록해야 한다..

- **계수-기반 페이지 교체**
각 페이지를 참조할 때마다 계수를 하게 만들면 두 가지의 기법을 만들 수 있다. 일반적으로 잘 쓰이지는 않는다(구현하는데 비용이 많이 들고 최적 페이지 교체 정책을 제대로 근사하지 못하기 때문).
	- LFU 알고리즘: **LFU(least frequently used)**알고리즘은 참조 횟수가 가장 작은 페이지를 교체하는 방법이다.
	- MFU 알고리즘: **MFU(most frequently used)**알고리즘은 가장 작은 참조 회수를 가진 페이지가 가장 최근 참조된 것이고 앞으로 사용될 것이라는 판단에 근거된 기법이다.

- **페이지-버퍼링 알고리즘**
시스템들이 가용 프레임 여러 개를 풀(pool)로 가지고 있다가, 페이지 폴트가 발생하면 예전과 마찬기지로 교체될 페이지를 찾지만, 교체될 페이지의 내용을 디스크에 기록하기 전에 가용 프레임에 새로운 페이지를 먼저 읽어 들이는 방법이다.

- **응용과 페이지 교체**
<br>

## 10.5 프레임의 할당

- **최소로 할당해야 할 프레임의 수**
최소한의 프레임은 할당해야만 하는 한 가지 이유는 성능과 관계된다. 각 프로세스에 할당되는 프레임 수가 줄어들면 페이지 폴트율은 증가하고 프로세스 실행은 늦어지게 된다. 또한 명령어 수행이 완료되기 전에 페이지 폴트가 발생하면 그 명령어는 재실행되어야 한다. 따라서 하나의 명령어가 참조하는 모든 페이지는 동시에 메모리에 올라와 있어야 그 명령어의 수행이 끝날 수 있다.
최소 프레임 수는 컴퓨터 아키텍처에 의해 정의된다.

- **할당 알고리즘**
프로세스에게 똑같은 양을 할당하는 **균등 할당(equal allocation)** 과 가용 메모리를 각 프로세스의 크기 비율에 맞추어 할당하는 **비례 할당(proportional allocation)** 이 있다.

- **전역 대 지역 할당**
전역 교체(global replacement): 프로세스가 교체할 프레임을 다른 프로세스에 속한 프레임을 포함한 모든 프레임을 대상으로 찾는 경우. 프로세스의 메모리에 있는 페이지 집합이 해당 프로레스의 페이징 동작뿐만 아니라 다른 프로세스의 페이징 동작에도 영향을 줄 수 있다는 단점이 있다.
지역 교체(loacl replacement): 프로세스가 자기에게 할당된 프레임 중에서만 교체될 희생자를 선택할 수 있는 경우. 자신의 할당된 프레임만 고려할 수 있기 때문에 우선순위가 낮은 다른 프로세스의 프레임을 뺏어올 수 없다는 단점이 있다.

- **비균등 메모리 접근**
<br>

## 10.6 스레싱
프로세스에 *"충분한"* 프레임이 없는 경우, 즉 작업 집합의 페이지를 지원하는 데 필요한 최소 프레임도 없는 경우엔 반복적으로 페이지 폴트가 발생하게 된다.
이러한 과도한 페이징 작업을 **스래싱(thrashing)** 이라고 부르고, 어떤 프로세스가 실제 실행보다 더 많은 시간을 페이징에 사용하고 있으면 스래싱이 발생했다고 말한다.

- **스래싱의 원인**
운영체제는 CPU의 이용률(utilization)을 감시한다. CPU 이용률이 너무 낮아지면 새로운 프로세스를 시스템에 더 추가해서 다중 프로그래밍 정도(degree of multiprogramming)을 높인다.
이때 새로운 프로세스의 실행으로 인해 더 많은 프레임을 가져와야 하고, 페이지 폴트를 발생시커 다른 프로세스로브터 프레임들을 가져오게 된다.
이러한 프로세스들이 페이지 스왑인/아웃을 위해 페이징 장치를 사용해야하고, 프로세스들이 페이징 장치를 기다리는 동안 CPU 이용률은 떨어진다.
여기서 CPU 스케줄러는 이용률이 떨어지는 것을 보고, 이용률을 높이기 위하여 새로운 프로세스를 추가하여 다중 프로그래밍의 정도를 더 *높인다*. 이는 스래싱을 발생시키고 시스템의 처리율은 대단히 낮아지고 페이지 폴트는 상당히 늘어난다(그림 10.20).
다중 프로그래밍의 정도가 일정 수준 이상으로 커지면 스래싱이 일어나게 되고 CPU의 이용률은 급격히 떨어진다. 따라서 이 지점에서는 CPU 이용률을 높이고 스래싱을 중지시키기 위해 다중 프로그래밍 정도를 **낮춰야만 한다.**
각 프로세스가 자신에게 할당된 프레임 세트에서만 가져올 프레임에서만 선택해야 하는 **지역 교체 알고리즘(우선순위 교체 알고리즘)** 을 사용하여 스래싱의 영향을 제한할 수 있다. 이는 하나의 프로세스가 스래싱을 시작하면 다른 프로세스의 프레임을 빼앗아 후자가 스래싱을 유발하도록 할 수 없다.
스래싱 현상을 방지하기 위해서는 각 프로세스가 필요로 하는 최소한의 프레임 개수를 보장해야 한다. 한 가지 전략은 프로세스가 실제로 사용하고 있는 프레임의 수가 몇개인가를 우선 알아보는 것이다. 이 방법은 프로세스 실행의 **지역성 모델(locality model)** 을 기반으로 한다. 이는 프로세스가 실행될 때에는 항상 어떤 특정한 지역에서만 메모리를 집중적으로 참조함을 말한다.
만약 필요로 하는 지역성의 크기보다 적은 프레임을 할당하게 되면, 그 프로세스는 접근해야 하는 모든 페이지를 메모리에 유지할 수 없기 때문에 지속해서 페이지 폴트를 발생시키게 되고 이는 스래싱을 유발한다.
<br>

- **작업 집합 모델**
**작업 집합 모델** 은 지역성을 토대로 하고 있다. 기본 아이디어는 최근 N만큼의 페이지 참조를 관찰하겠다는 것이다.
작업 집합의 정확도는 N의 선택에 따라 좌우한다. N값을 선택하고 나면 운영체제는 각 프로세스의 작업 집합을 감시하면서 각 프로세스에 작업 집합 크기에 맞는 충분한 프레임을 할당한다.
<br>

- **페이지 폴트 빈도**
작업 집합 모델보다 더 직접적으로 스래싱을 조절하는 **페이지 폴트 빈도(PFF)** 는, 페이지 폴트율의 상한과 하한을 정해 놓고, 만약 페이지 폴트율이 상한을 넘으면 해당 프로세스에 프레임을 더 할당해 주고, 반대의 경우에는 프레임 수를 줄인다.
만약 페이지 폴트율이 높아졌는데 그 프로세스에 줄 수 있는, 가용 프레임이 없으면, 한 프로세스를 선택하여 그 프로세스를 예비 저장장치로 스왑 아웃시켜야 한다. 이를 통해 생긴 프레임들은 높은 페이지 폴트율을 갖는 다른 프로세스들에게 분배된다.
<br>

## 10.7 메모리 압축
**메모리 압축(memory compress)** 는 수정된 프레임을 스왑 공간으로 페이징 아웃하지 않고 여러 프레임을 하나의 프레임으로 압축하는 페이징의 대안이다.

## 10.8 커널 메모리의 할당
커널 메모리는 보통 사용자 모드 프로세스에 할당해 주기 위한 페이지 리스트와는 별도의 메모리 풀에서 할당받는다.
- 커널은 다양한 크기의 자료구조를 위해 메모리를 할당받는다. 이 자료구조들은 페이지 크기보다 작은 크기를 가지기도 한다. 그 때문에 커널은 메모리를 조심스럽게 사용하여야 하고 단편화에 의한 낭비를 최소화하고자 한다. 많은 운영체제가 커널 코드나 데이터를 페이징하지 않기 때문에 특히 더 중요하다
- 사용자 모드 프로세스에 할당되는 페이지들은 물리 메모리상에서 굳이 연속된 것일 필요는 없다. 그러나 가상 메모리 인터페이스를 통하지 않고 물리 메모리에 직접 접근하는 특정 하드웨어 장치는 물리적으로 연속적인 메모리가 있어야 하는 경우가 있다.

- **버디 시스템**
물리적을 연속된 페이지들로 이루어진 고정된 크기의 세그먼트로부터 메모리를 할당한다. 메모리는 이 세그먼트로부터 **2의 거듭제곱 할당기** 에 의해 2의 거듭제곱 단위로 할당된다. 2의 거듭제곱 크기가 아닌 메모리 요구의 경우 가장 가까운 2의 거듭제곱 크기로 올림 된다. 버디 시스템의 이점은 **합병(coalescing)** 으로, 서로 인접한 버디들이 손쉽게 하나의 큰 세그먼트로 합쳐질 수 있다. 단점으로는 2의 거듭제곱 단위로 할당되기 때문에 단편화가 일어난다.
<br>

- **슬랩 할당**
**슬랩(slab)** 은 하나 또는 그 이상의 연속된 페이지들로 구성된다. **캐시(cache)** 는 하나 혹은 그 이상의 슬랩들로 구성된다. 캐시가 생성되면 초기에는 `free`로 표시된 몇 개의 객체들이 캐시에 할당된다. 커널 자료구조를 위한 객체가 필요하면 `free` 객체 중 하나를 캐시로부터 할당해 준다. 할당된 캐시는 `used` 로 표시된다.
Linux에서 슬랩은 다음과 같은 세 가지 상태 중 한 상태에 있게 된다.
1. FULL. 슬랩 내 모든 객체가 `used`로 표시됨
2. EMPTY. 슬랩 내의 모든 객체가 `free`로 표시됨
3. PARTIAL. `used`, `free` 객체가 섞여있다

슬랩 할당기는 먼저 `partial`의 `free`객체를 이용해 처리하려고 시도하고 `partial` 이 없을 시 `empty` 로부터 `free` 객체를 할당한다.
슬랩 할당기는 두 가지 주요 장점이 있다
1. 단편화에 의해 낭비되는 메모리가 없다. 각 커널 자료구조가 그에 해당하는 캐시를 가지고 각 캐시는 그에 의해 처리되는 객체의 크기로 나누어진 덩어리들로 구성되므로 단편화는 문제가 되지 않는다. -> 커널이 메모리 할당을 요구할 때마다 슬랩 할당기는 정확히 필요한 만큼의 메모리만을 할당한다.
2. 메모리 요청이 빠르게 처리된다. 따라서 슬랩 할당기는 할당과 해제가 빈번한 자료구조 객체를 관리하는데 특히 효율적이다. 커널 내에서 이러한 상황은 자주 발생한다. 메모리 할당과 해제는 상당히 시간이 소요되는 작업일 수 있다. 그러나 객체들은 미리 생성되어 있고 캐시에서 쉽게 할당할 수 있다. 더 나아가 커널이 특정 객체를 다 사용하고 해ㅐ제하면 `free`로 표시된 상태로 캐시로 반환되어 다음 요구 시 즉시 할당 가능하게 된다.
<br>

## 10.9 기타 고려 사항

- **프리페이징**
이미 존재하는 시스템의 운영체제는 페이지 크기를 바꾸는 것이 거의 불가능하다.페이지 크기는 항상 2의 제곱이고, 일반적으로 `4096(2^12)` 에서 `4194304(2^22)`바이트나 워드 범위이다.
페이지 크기에 영향을 주는 요소중 하나인 페이지 테이블의 크기는 페이지가 클수록 페이지 테이블의 크기가 감소한다. 반면에 할당해 준 메모리 사용 효율을 위해서는 작은 페이지가 더 좋다(내부 단편화).
또 큰 페이지는 I/O시간을 최소화할수 있고, 작은 페이지는 지역성을 향상시켜줘 전체 I/O는 줄어들 것이다(필요한 정보만을 선별해 메모리로 가져올 수 있는 `정밀도(resolution)`).
추가로, 페이지 폴트를 고려할 경우 큰 페이지가 더 좋다.

- **TLB Reach**
TLB, 가상 메모리 참조 중 페이지 테이블에 가지 않더라도 TLB상에서 주소 변환을 수행할 수 있는 기법. TLB hit을 올리려면 TLB 항목을 늘리면 되지만, 비용이 크게 들기 때문에 쉽지 않다.
TLB reach는 TLB로부터 접근할 수 있는 메모리 공간의 크기를 뜻한다. TLB reach를 늘리려면 페이지 크기를 늘리거나 여러 페이지 크기를 제공하는 것이다.

- **역 페이지 테이블**
가상-물리 주소 변환을 추적하는데 필요한 물리 메모리의 양을 줄이는 역 페이지 테이블 개념은, 각 페이지 프레임에 어떤 가상 메모리 페이지가 저장되어 있는지의 정보만 유지하면 되므로 필요한 물리 메모리 양을 줄인다.

- **프로그램 구조**
I/O는 별도의 처리기에 의해서 실행되는데, 이때 CPU가 I/O가 사용할 프레임을 다른 프로세스에게 넘겨주었을때 문제가 발생한다. 이의 해결책은 페이지를 `잠금 비트(lock-bit)`를 이용해 메모리에서 **잠금(lock)**하는 것이다.
> GPT의 답변..
가상 메모리에서 I/O 상호 잠금은 주로 페이징(Paging)이나 세그멘테이션(Segmentation)과 관련이 있습니다. 가상 메모리는 물리적 메모리와 디스크(스왑 공간)를 조합하여 프로세스에게 더 큰 메모리 공간을 제공하는 기술이며, 이때 I/O 상호 잠금이 어떻게 작용하는지에 대해 설명해보겠습니다.<br>
페이지 폴트와 스왑:
프로세스가 가상 주소 공간에서 접근하는 페이지가 물리적 메모리에 없으면 페이지 폴트가 발생합니다. 이때, 필요한 페이지가 디스크의 스왑 영역에 있다면 해당 페이지를 물리적 메모리로 가져와야 합니다.<br>
I/O 상호 잠금 동작:
여러 프로세스가 동시에 I/O 연산을 수행하려 할 때 충돌이 발생할 수 있습니다. 특히, 여러 페이지를 스왑인/스왑아웃하는 경우가 이에 해당합니다. I/O 상호 잠금은 한 번에 하나의 페이지만 스왑인/스왑아웃할 수 있도록 보장합니다. 이를 통해 데이터의 일관성을 유지하고 충돌을 방지합니다.<br>
페이지 단위의 락(Lock):
페이지를 스왑인/스왑아웃할 때 해당 페이지에 대한 락을 걸어 다른 프로세스가 동시에 접근하지 못하도록 합니다. 이 락은 I/O 상호 잠금을 나타내며, 다른 프로세스는 락이 해제될 때까지 대기해야 합니다.<br>
성능 측면:
I/O 상호 잠금이 필요한 상황에서는 일부 프로세스가 대기할 수 있으므로 성능에 영향을 미칠 수 있습니다. 이를 최소화하기 위해 효율적인 페이지 교체 알고리즘이나 I/O 예측 기법 등이 사용됩니다. 가상 메모리에서의 I/O 상호 잠금은 주로 페이지 스왑과 관련이 있으며, 이를 통해 다중 프로세스 간에 안정적인 메모리 공유와 일관성을 유지하면서 효율적인 가상 메모리 관리가 가능해집니다.
